---
title: "R Notebook"
output: html_notebook
---
```{r}
#Load libraries
library(rpart)
library(rpart.plot)
library(randomForest)
library(class)
library(e1071)
library(FNN)
```



```{r}
#read data
originalKepplerData = read.csv("cumulative.csv") #read data
#View(head(originalKepplerData))
summary(originalKepplerData)
factored_keppler_data = originalKepplerData
factored_keppler_data$koi_disposition = factor(originalKepplerData$koi_disposition) #factor character data
originalKepplerData$koip_disposition
factored_keppler_data$koi_pdisposition = factor(originalKepplerData$koi_pdisposition)
head(factored_keppler_data)
remove_KOI_tech_factoered = subset(factored_keppler_data, select = -c(koi_teq_err1)) #remove all-NA columns
remove_KOI_tech_factoered = subset(remove_KOI_tech_factoered, select = -c(koi_teq_err2))
summary(remove_KOI_tech_factoered)
#View(remove_KOI_tech_factoered)
remove_NAs = na.exclude(remove_KOI_tech_factoered) #remove NAs
summary(remove_NAs)
identifiers_removed = subset(remove_NAs, select = -c(rowid, kepid, kepoi_name, kepler_name, koi_pdisposition, koi_score))
#get rid of unique identifiers, as well as ones that can only be calculated once you know the outcome, like Koi_Pdisposition and koi_score

#Also needs to remove flags, these can only be known after status is confirmed
identifiers_removed = subset(identifiers_removed, select = -c(koi_fpflag_ss, koi_fpflag_ec, koi_fpflag_co, koi_fpflag_nt, koi_tce_plnt_num, koi_tce_delivname))



#separate into labeled and unlabeled data
candidates_final = identifiers_removed[identifiers_removed$koi_disposition ==
                                         "CANDIDATE", ] #separate out just the candidates
labeled_final = identifiers_removed[identifiers_removed$koi_disposition !=
                                      "CANDIDATE", ]
summary(candidates_final)
summary(labeled_final)

head(candidates_final)
summary(candidates_final)
```
First, do all models that don't require normalization
```{r}
for (fold in 1:5) {
  set.seed(fold)
  
  num_samples = dim(labeled_final)[1]
  sampling.rate = 0.8
  training = sample(1:num_samples, sampling.rate * num_samples, replace = FALSE)
  trainingSet = subset(labeled_final[training,])
  testing = setdiff(1:num_samples, training)
  testingSet = subset(labeled_final[testing, ])
  
  decTreeModel = rpart(koi_disposition ~ ., data = trainingSet)
  rpart.plot(decTreeModel)
  
  decTreePredictions = predict(decTreeModel, testingSet, type = "class")
  sizeTestSet = dim(testingSet)[1]
  decTreePredictions
  decTreeModel_error = sum(decTreePredictions != testingSet$koi_disposition)
  
  misclassificationRateDecTree = decTreeModel_error/sizeTestSet
  misclassificationRateDecTree
    
  #Random Forest Model (Error in this model)
  #RandForestModel=randomForest(koi_disposition~., data=trainingSet,importance=TRUE, ntree=100)
  #summary(trainingSet)
  #class(RandForestModel)
  #predictionsRandForest=predict(RandForestModel,testingSet)
  #errorRandForest = sum(predictionsRandForest!=testingSet$koi_disposition)
  #misclassificationRateRandomForest=errorRandForest/sizeTestSet
  #misclassificationRateRandomForest  

  #SVM Model
  svmModel=svm(koi_disposition~.,data=trainingSet,kernel="linear")
  predictedlabelsSVM=predict(svmModel,testingSet)
  errorSVM=sum(predictedlabelsSVM!=testingSet$koi_disposition)
  misclassification_rateSVM=errorSVM/sizeTestSet
  print(misclassification_rateSVM)
  
  #Logistic Regression Model
  LogisticReg = glm(koi_disposition ~ ., data = trainingSet, family = binomial(logit))
  predicions = predict(LogisticReg, testingSet, type = "response")
  predictedLabels = rep(0, sizeTestSet) 
  predictedLabels = ifelse(predicions > 0.5, 'FALSE POSITIVE', 'CONFIRMED') 
  error = sum(predictedLabels != testingSet$koi_disposition)
  misclassificationRateLR = error / sizeTestSet
  print(misclassificationRateLR)

}
```
#Normalized
```{r}
head(labeled_final)
dim(labeled_final)
for (fold in 1:5) {
  set.seed(fold)
  scaled_data = data.frame(scale(labeled_final[,2:36]))
  scaled_data$koi_disposition = labeled_final$koi_disposition
  summary(scaled_data)
  num_samples = dim(scaled_data)[1]
  sampling.rate = 0.2
  training = sample(1:num_samples, sampling.rate * num_samples, replace = FALSE)
  trainingSet.norm = subset(scaled_data[training,])
  testing = setdiff(1:num_samples, training)
  testingSet.norm = subset(scaled_data[testing, ])
  
  koiDP.name = "koi_disposition"
  variable.names = rep(0,numCols)
  
  
  numCols = dim(testingSet.norm)[2]
  variable.names = colnames(testingSet.norm)[1:numCols-1]
 
  variable.names
  for (i in 1:length(variable.names)){
    error = grepl( "_err", variable.names[i], fixed = TRUE)
    if (error){
      variable.names[i] = NA
    }
    
  }
  
  variable.names = na.omit(variable.names)
  variable.names = variable.names[1:15]
  variable.names
  
  library(formulaic)
  nn.form <-
  create.formula(outcome.name = koiDP.name,
                 input.names = variable.names)
  nn.form
  library(neuralnet)
  nnModel = neuralnet(
    nn.form,
    data = trainingSet.norm,
    hidden = c(4, 2),
    linear.output = FALSE
  )
 
 
 
}
```

```{r}

```
 
 